[2023-09-03T17:53:20.325+0000] {processor.py:157} INFO - Started process (PID=3898) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:20.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:53:20.327+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:53:20.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:20.335+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:53:20.334+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:53:20.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:20.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.027 seconds
[2023-09-03T17:53:50.587+0000] {processor.py:157} INFO - Started process (PID=4051) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:50.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:53:50.589+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:53:50.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:50.597+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:53:50.596+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:53:50.598+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:53:50.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.033 seconds
[2023-09-03T17:54:20.931+0000] {processor.py:157} INFO - Started process (PID=4293) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:20.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:54:20.937+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:54:20.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:20.969+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:54:20.960+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:54:20.971+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:21.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.101 seconds
[2023-09-03T17:54:51.382+0000] {processor.py:157} INFO - Started process (PID=4428) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:51.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:54:51.384+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:54:51.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:51.393+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:54:51.392+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:54:51.393+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:54:51.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.034 seconds
[2023-09-03T17:55:21.605+0000] {processor.py:157} INFO - Started process (PID=4446) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:21.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:55:21.607+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:55:21.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:21.616+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:55:21.615+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:55:21.616+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:21.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.034 seconds
[2023-09-03T17:55:51.790+0000] {processor.py:157} INFO - Started process (PID=4463) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:51.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:55:51.792+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:55:51.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:51.800+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:55:51.799+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:55:51.801+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:55:51.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T17:56:22.072+0000] {processor.py:157} INFO - Started process (PID=4490) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:22.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:56:22.073+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:56:22.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:22.080+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:56:22.079+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:56:22.081+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:22.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.026 seconds
[2023-09-03T17:56:52.306+0000] {processor.py:157} INFO - Started process (PID=4512) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:52.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:56:52.308+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:56:52.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:52.316+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:56:52.315+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:56:52.317+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:56:52.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.034 seconds
[2023-09-03T17:57:22.517+0000] {processor.py:157} INFO - Started process (PID=4529) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:22.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:57:22.520+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:57:22.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:22.528+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:57:22.527+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:57:22.529+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:22.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T17:57:52.761+0000] {processor.py:157} INFO - Started process (PID=4610) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:52.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:57:52.763+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:57:52.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:52.771+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:57:52.770+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:57:52.771+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:57:52.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T17:58:23.086+0000] {processor.py:157} INFO - Started process (PID=4864) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:23.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:58:23.090+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:58:23.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:23.107+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:58:23.105+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:58:23.109+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:23.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.061 seconds
[2023-09-03T17:58:53.445+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:53.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:58:53.447+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:58:53.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:53.454+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:58:53.453+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:58:53.454+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:58:53.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.026 seconds
[2023-09-03T17:59:23.722+0000] {processor.py:157} INFO - Started process (PID=4966) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:23.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:59:23.724+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:59:23.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:23.734+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:59:23.733+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:59:23.735+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:23.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.033 seconds
[2023-09-03T17:59:53.938+0000] {processor.py:157} INFO - Started process (PID=5012) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:53.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T17:59:53.940+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:59:53.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:53.947+0000] {logging_mixin.py:151} INFO - [2023-09-03T17:59:53.946+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T17:59:53.948+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T17:59:53.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:00:24.131+0000] {processor.py:157} INFO - Started process (PID=5033) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:24.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:00:24.132+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:00:24.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:24.140+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:00:24.139+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:00:24.141+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:24.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:00:54.329+0000] {processor.py:157} INFO - Started process (PID=5050) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:54.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:00:54.332+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:00:54.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:54.342+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:00:54.341+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:00:54.342+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:00:54.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:01:05.440+0000] {processor.py:157} INFO - Started process (PID=5060) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:05.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:01:05.443+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:01:05.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:05.451+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:01:05.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:01:05.451+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:05.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:01:35.681+0000] {processor.py:157} INFO - Started process (PID=5077) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:35.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:01:35.683+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:01:35.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:35.690+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:01:35.689+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:01:35.690+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:01:35.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:02:05.919+0000] {processor.py:157} INFO - Started process (PID=5094) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:05.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:02:05.921+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:02:05.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:05.929+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:02:05.928+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:02:05.930+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:05.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:02:36.105+0000] {processor.py:157} INFO - Started process (PID=5111) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:36.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:02:36.107+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:02:36.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:36.115+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:02:36.114+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:02:36.116+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:02:36.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.030 seconds
[2023-09-03T18:03:06.279+0000] {processor.py:157} INFO - Started process (PID=5128) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:06.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:03:06.281+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:06.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:06.292+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:06.290+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:03:06.292+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:06.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:03:11.311+0000] {processor.py:157} INFO - Started process (PID=5140) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:11.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:03:11.313+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:11.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:11.323+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:11.322+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:03:11.324+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:11.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:03:36.522+0000] {processor.py:157} INFO - Started process (PID=5150) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:36.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:03:36.524+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:36.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:36.528+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:36.527+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 43
    op_args=[5, 3],
    ^
SyntaxError: invalid syntax
[2023-09-03T18:03:36.528+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:36.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.026 seconds
[2023-09-03T18:03:42.559+0000] {processor.py:157} INFO - Started process (PID=5162) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:42.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:03:42.561+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:42.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:42.576+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:42.574+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:03:42.577+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:42.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.043 seconds
[2023-09-03T18:03:52.651+0000] {processor.py:157} INFO - Started process (PID=5167) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:52.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:03:52.653+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:52.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:52.661+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:03:52.660+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:03:52.662+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:03:52.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:04:06.758+0000] {processor.py:157} INFO - Started process (PID=5177) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:06.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:04:06.759+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:06.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:06.763+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:06.762+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 49
    op_args=[Transform.output]
    ^
SyntaxError: invalid syntax
[2023-09-03T18:04:06.763+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:06.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.024 seconds
[2023-09-03T18:04:18.838+0000] {processor.py:157} INFO - Started process (PID=5189) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:18.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:04:18.842+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:18.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:18.859+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:18.857+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:04:18.860+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:18.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.043 seconds
[2023-09-03T18:04:23.891+0000] {processor.py:157} INFO - Started process (PID=5194) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:23.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:04:23.893+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:23.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:23.903+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:23.902+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:04:23.903+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:23.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:04:54.108+0000] {processor.py:157} INFO - Started process (PID=5212) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:54.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:04:54.110+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:54.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:54.118+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:04:54.117+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:04:54.119+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:04:54.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:05:24.324+0000] {processor.py:157} INFO - Started process (PID=5229) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:24.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:05:24.326+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:05:24.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:24.334+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:05:24.333+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:05:24.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:24.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.030 seconds
[2023-09-03T18:05:54.538+0000] {processor.py:157} INFO - Started process (PID=5246) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:54.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:05:54.539+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:05:54.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:54.548+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:05:54.547+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:05:54.549+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:05:54.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.031 seconds
[2023-09-03T18:06:24.779+0000] {processor.py:157} INFO - Started process (PID=5263) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:24.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:06:24.781+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:06:24.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:24.790+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:06:24.788+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:06:24.790+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:24.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.031 seconds
[2023-09-03T18:06:55.035+0000] {processor.py:157} INFO - Started process (PID=5280) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:55.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:06:55.037+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:06:55.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:55.045+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:06:55.044+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:06:55.045+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:06:55.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.028 seconds
[2023-09-03T18:07:25.257+0000] {processor.py:157} INFO - Started process (PID=5297) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:25.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:07:25.259+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:07:25.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:25.269+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:07:25.268+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:07:25.270+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:25.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.033 seconds
[2023-09-03T18:07:55.473+0000] {processor.py:157} INFO - Started process (PID=5314) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:55.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:07:55.475+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:07:55.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:55.483+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:07:55.482+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:07:55.484+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:07:55.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.031 seconds
[2023-09-03T18:08:25.689+0000] {processor.py:157} INFO - Started process (PID=5331) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:25.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:08:25.692+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:08:25.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:25.699+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:08:25.698+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:08:25.700+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:25.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:08:55.887+0000] {processor.py:157} INFO - Started process (PID=5348) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:55.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:08:55.889+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:08:55.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:55.897+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:08:55.895+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:08:55.897+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:08:55.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.030 seconds
[2023-09-03T18:09:26.067+0000] {processor.py:157} INFO - Started process (PID=5365) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:26.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:09:26.069+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:09:26.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:26.077+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:09:26.076+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:09:26.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:26.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.030 seconds
[2023-09-03T18:09:56.240+0000] {processor.py:157} INFO - Started process (PID=5382) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:56.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:09:56.242+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:09:56.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:56.250+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:09:56.249+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:09:56.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:09:56.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.031 seconds
[2023-09-03T18:10:26.417+0000] {processor.py:157} INFO - Started process (PID=5399) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:26.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:10:26.419+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:10:26.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:26.428+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:10:26.427+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:10:26.428+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:26.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.036 seconds
[2023-09-03T18:10:56.619+0000] {processor.py:157} INFO - Started process (PID=5416) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:56.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:10:56.621+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:10:56.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:56.630+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:10:56.629+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:10:56.630+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:10:56.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.033 seconds
[2023-09-03T18:11:26.848+0000] {processor.py:157} INFO - Started process (PID=5433) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:26.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:11:26.851+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:11:26.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:26.859+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:11:26.858+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 1, in <module>
    import findspark
ModuleNotFoundError: No module named 'findspark'
[2023-09-03T18:11:26.860+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:26.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.034 seconds
[2023-09-03T18:11:57.070+0000] {processor.py:157} INFO - Started process (PID=5450) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:57.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:11:57.072+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:11:57.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:57.082+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:11:57.081+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:11:57.083+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:11:57.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.030 seconds
[2023-09-03T18:12:27.303+0000] {processor.py:157} INFO - Started process (PID=5467) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:27.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:12:27.306+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:12:27.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:27.313+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:12:27.312+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:12:27.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:27.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.032 seconds
[2023-09-03T18:12:57.524+0000] {processor.py:157} INFO - Started process (PID=5484) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:57.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:12:57.526+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:12:57.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:57.535+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:12:57.533+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:12:57.535+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:12:57.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.031 seconds
[2023-09-03T18:13:27.724+0000] {processor.py:157} INFO - Started process (PID=5501) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:27.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:13:27.726+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:13:27.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:27.735+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:13:27.733+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:13:27.735+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:27.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.033 seconds
[2023-09-03T18:13:57.930+0000] {processor.py:157} INFO - Started process (PID=5518) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:57.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:13:57.933+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:13:57.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:57.944+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:13:57.943+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:13:57.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:13:57.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.040 seconds
[2023-09-03T18:14:28.127+0000] {processor.py:157} INFO - Started process (PID=5535) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:28.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:14:28.130+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:14:28.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:28.140+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:14:28.139+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:14:28.140+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:28.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.037 seconds
[2023-09-03T18:14:58.325+0000] {processor.py:157} INFO - Started process (PID=5568) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:58.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:14:58.328+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:14:58.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:58.336+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:14:58.334+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:14:58.336+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:14:58.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.029 seconds
[2023-09-03T18:15:28.516+0000] {processor.py:157} INFO - Started process (PID=5585) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:28.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:15:28.518+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:15:28.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:28.526+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:15:28.525+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
ModuleNotFoundError: No module named 'pyspark'
[2023-09-03T18:15:28.527+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:28.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.027 seconds
[2023-09-03T18:15:58.673+0000] {processor.py:157} INFO - Started process (PID=5607) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:58.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:15:58.675+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:15:58.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:58.759+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:15:58.757+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 3, in <module>
    from pyspark.sql import SparkSession
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/__init__.py", line 115, in <module>
    from pyspark.sql import SQLContext, HiveContext, Row
ModuleNotFoundError: No module named 'pyspark.sql'
[2023-09-03T18:15:58.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:15:58.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.105 seconds
[2023-09-03T18:16:28.845+0000] {processor.py:157} INFO - Started process (PID=5624) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:28.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:16:28.848+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:16:28.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:28.908+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:16:28.906+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 7, in <module>
    import time_uuid
ModuleNotFoundError: No module named 'time_uuid'
[2023-09-03T18:16:28.908+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:28.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.089 seconds
[2023-09-03T18:16:59.128+0000] {processor.py:157} INFO - Started process (PID=5641) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:59.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:16:59.130+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:16:59.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:59.198+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:16:59.197+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 7, in <module>
    import time_uuid
ModuleNotFoundError: No module named 'time_uuid'
[2023-09-03T18:16:59.199+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:16:59.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.089 seconds
[2023-09-03T18:17:29.381+0000] {processor.py:157} INFO - Started process (PID=5666) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:29.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:17:29.383+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:17:29.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:29.558+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:17:29.555+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 16, in <module>
    spark = SparkSession.builder\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 186, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 376, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 133, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 325, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    raise Exception("Java gateway process exited before sending its port number")
Exception: Java gateway process exited before sending its port number
[2023-09-03T18:17:29.560+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:29.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.209 seconds
[2023-09-03T18:17:59.742+0000] {processor.py:157} INFO - Started process (PID=5690) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:59.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:17:59.744+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:17:59.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:59.913+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:17:59.909+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 16, in <module>
    spark = SparkSession.builder\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 186, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 376, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 133, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 325, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    raise Exception("Java gateway process exited before sending its port number")
Exception: Java gateway process exited before sending its port number
[2023-09-03T18:17:59.916+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:17:59.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.208 seconds
[2023-09-03T18:18:30.009+0000] {processor.py:157} INFO - Started process (PID=5714) to work on /opt/airflow/dags/dags_setup.py
[2023-09-03T18:18:30.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dags_setup.py for tasks to queue
[2023-09-03T18:18:30.011+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:18:30.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:18:30.206+0000] {logging_mixin.py:151} INFO - [2023-09-03T18:18:30.205+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/opt/airflow/dags/ETL_Cassandra_S3.py", line 16, in <module>
    spark = SparkSession.builder\
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/sql/session.py", line 186, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 376, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 133, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/context.py", line 325, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.8/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    raise Exception("Java gateway process exited before sending its port number")
Exception: Java gateway process exited before sending its port number
[2023-09-03T18:18:30.207+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dags_setup.py
[2023-09-03T18:18:30.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dags_setup.py took 0.223 seconds
[2023-09-04T01:32:13.197+0700] {processor.py:157} INFO - Started process (PID=37348) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:32:13.198+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:32:13.199+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:32:13.198+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:32:21.852+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:32:21.804+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=26dbf9e6): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=26dbf9e6): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.writeListener(ChannelHandlerRequest.java:87)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:76)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.send(ProtocolInitHandler.java:193)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler.onRealConnect(ProtocolInitHandler.java:124)
		at com.datastax.oss.driver.internal.core.channel.ConnectInitHandler.lambda$connect$0(ConnectInitHandler.java:57)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
		Suppressed: com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:9042
		Caused by: java.net.ConnectException: Connection refused
			at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
			at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
			at com.datastax.oss.driver.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
			at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
			at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:829)
	Caused by: java.nio.channels.ClosedChannelException
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:921)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
		at com.datastax.oss.driver.shaded.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:75)
		... 20 more
[2023-09-04T01:32:21.896+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:32:21.913+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.719 seconds
[2023-09-04T01:36:43.687+0700] {processor.py:157} INFO - Started process (PID=38792) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:36:43.688+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:36:43.688+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:36:43.688+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:36:52.304+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:36:52.256+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=6678211b): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=6678211b): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.writeListener(ChannelHandlerRequest.java:87)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:76)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.send(ProtocolInitHandler.java:193)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler.onRealConnect(ProtocolInitHandler.java:124)
		at com.datastax.oss.driver.internal.core.channel.ConnectInitHandler.lambda$connect$0(ConnectInitHandler.java:57)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
		Suppressed: com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:9042
		Caused by: java.net.ConnectException: Connection refused
			at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
			at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
			at com.datastax.oss.driver.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
			at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
			at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:829)
	Caused by: java.nio.channels.ClosedChannelException
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:921)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
		at com.datastax.oss.driver.shaded.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:75)
		... 20 more
[2023-09-04T01:36:52.348+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:36:52.364+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.678 seconds
[2023-09-04T01:37:22.722+0700] {processor.py:157} INFO - Started process (PID=39183) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:22.723+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:37:22.724+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:37:22.723+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:31.768+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:37:31.716+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=401fc8da): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=401fc8da): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.writeListener(ChannelHandlerRequest.java:87)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:76)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.send(ProtocolInitHandler.java:193)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler.onRealConnect(ProtocolInitHandler.java:124)
		at com.datastax.oss.driver.internal.core.channel.ConnectInitHandler.lambda$connect$0(ConnectInitHandler.java:57)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
		Suppressed: com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:9042
		Caused by: java.net.ConnectException: Connection refused
			at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
			at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
			at com.datastax.oss.driver.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
			at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
			at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:829)
	Caused by: java.nio.channels.ClosedChannelException
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:921)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
		at com.datastax.oss.driver.shaded.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:75)
		... 20 more
[2023-09-04T01:37:31.812+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:31.832+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 9.114 seconds
[2023-09-04T01:37:44.706+0700] {processor.py:157} INFO - Started process (PID=39952) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:44.706+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:37:44.707+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:37:44.706+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:53.284+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:37:53.236+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=51b51255): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=51b51255): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.writeListener(ChannelHandlerRequest.java:87)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:76)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.send(ProtocolInitHandler.java:193)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler.onRealConnect(ProtocolInitHandler.java:124)
		at com.datastax.oss.driver.internal.core.channel.ConnectInitHandler.lambda$connect$0(ConnectInitHandler.java:57)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
		Suppressed: com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:9042
		Caused by: java.net.ConnectException: Connection refused
			at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
			at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
			at com.datastax.oss.driver.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
			at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
			at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:829)
	Caused by: java.nio.channels.ClosedChannelException
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:921)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
		at com.datastax.oss.driver.shaded.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:75)
		... 20 more
[2023-09-04T01:37:53.328+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:37:53.355+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.651 seconds
[2023-09-04T01:38:01.593+0700] {processor.py:157} INFO - Started process (PID=40279) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:01.593+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:38:01.594+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:38:01.594+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:10.076+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:38:10.028+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=2b6ae41): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=2b6ae41): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|connecting...] Protocol initialization request, step 1 (OPTIONS): failed to send request (java.nio.channels.ClosedChannelException)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.writeListener(ChannelHandlerRequest.java:87)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:183)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:95)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:30)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:76)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.send(ProtocolInitHandler.java:193)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler.onRealConnect(ProtocolInitHandler.java:124)
		at com.datastax.oss.driver.internal.core.channel.ConnectInitHandler.lambda$connect$0(ConnectInitHandler.java:57)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:570)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:549)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
		Suppressed: com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:9042
		Caused by: java.net.ConnectException: Connection refused
			at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
			at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
			at com.datastax.oss.driver.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
			at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
			at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
			at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
			at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
			at java.base/java.lang.Thread.run(Thread.java:829)
	Caused by: java.nio.channels.ClosedChannelException
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:921)
		at com.datastax.oss.driver.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:897)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1372)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:742)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:728)
		at com.datastax.oss.driver.shaded.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:127)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:750)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:765)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:790)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:758)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.send(ChannelHandlerRequest.java:75)
		... 20 more
[2023-09-04T01:38:10.120+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:10.145+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.557 seconds
[2023-09-04T01:38:40.294+0700] {processor.py:157} INFO - Started process (PID=41065) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:40.295+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:38:40.296+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:38:40.296+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:50.579+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:38:50.577+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o39.load.
: java.io.IOException: Failed to open native connection to Cassandra at {localhost:9042} :: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=4f8d5468): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|id: 0x598f5089, L:/127.0.0.1:37598 - R:localhost/127.0.0.1:9042] Protocol initialization request, step 1 (OPTIONS): unexpected failure (com.datastax.oss.driver.api.core.connection.ClosedConnectionException: Lost connection to remote peer)]
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:173)
	at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$1(CassandraConnector.scala:161)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:81)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:103)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
	at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
	at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
	at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$1(DataFrameReader.scala:274)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:248)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:221)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: com.datastax.oss.driver.api.core.AllNodesFailedException: Could not reach any contact point, make sure you've provided valid addresses (showing first 1 nodes, use getAllErrors() for more): Node(endPoint=localhost/127.0.0.1:9042, hostId=null, hashCode=4f8d5468): [com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|id: 0x598f5089, L:/127.0.0.1:37598 - R:localhost/127.0.0.1:9042] Protocol initialization request, step 1 (OPTIONS): unexpected failure (com.datastax.oss.driver.api.core.connection.ClosedConnectionException: Lost connection to remote peer)]
	at com.datastax.oss.driver.api.core.AllNodesFailedException.copy(AllNodesFailedException.java:141)
	at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149)
	at com.datastax.oss.driver.api.core.session.SessionBuilder.build(SessionBuilder.java:703)
	at com.datastax.spark.connector.cql.DefaultConnectionFactory$.createSession(CassandraConnectionFactory.scala:143)
	at com.datastax.spark.connector.cql.CassandraConnector$.createSession(CassandraConnector.scala:167)
	... 26 more
	Suppressed: com.datastax.oss.driver.api.core.connection.ConnectionInitException: [s0|control|id: 0x598f5089, L:/127.0.0.1:37598 - R:localhost/127.0.0.1:9042] Protocol initialization request, step 1 (OPTIONS): unexpected failure (com.datastax.oss.driver.api.core.connection.ClosedConnectionException: Lost connection to remote peer)
		at com.datastax.oss.driver.internal.core.channel.ProtocolInitHandler$InitRequest.fail(ProtocolInitHandler.java:354)
		at com.datastax.oss.driver.internal.core.channel.ChannelHandlerRequest.onFailure(ChannelHandlerRequest.java:104)
		at com.datastax.oss.driver.internal.core.channel.InFlightHandler.fail(InFlightHandler.java:381)
		at com.datastax.oss.driver.internal.core.channel.InFlightHandler.abortAllInFlight(InFlightHandler.java:371)
		at com.datastax.oss.driver.internal.core.channel.InFlightHandler.abortAllInFlight(InFlightHandler.java:353)
		at com.datastax.oss.driver.internal.core.channel.InFlightHandler.channelInactive(InFlightHandler.java:331)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
		at com.datastax.oss.driver.shaded.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:389)
		at com.datastax.oss.driver.shaded.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:354)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
		at com.datastax.oss.driver.shaded.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
		at com.datastax.oss.driver.shaded.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
		at com.datastax.oss.driver.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
		at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		... 1 more
	Caused by: com.datastax.oss.driver.api.core.connection.ClosedConnectionException: Lost connection to remote peer
[2023-09-04T01:38:50.580+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:38:50.595+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 10.305 seconds
[2023-09-04T01:39:20.701+0700] {processor.py:157} INFO - Started process (PID=41552) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:39:20.702+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:39:20.703+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:39:20.703+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:39:29.044+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:39:29.039+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:39:29.046+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:39:29.059+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.362 seconds
[2023-09-04T01:39:59.197+0700] {processor.py:157} INFO - Started process (PID=42209) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:39:59.197+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:39:59.197+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:39:59.197+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:40:08.113+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:40:08.107+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:40:08.116+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:40:08.132+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.937 seconds
[2023-09-04T01:40:38.309+0700] {processor.py:157} INFO - Started process (PID=42655) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:40:38.310+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:40:38.313+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:40:38.312+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:40:46.669+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:40:46.665+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:40:46.671+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:40:46.685+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.380 seconds
[2023-09-04T01:41:16.791+0700] {processor.py:157} INFO - Started process (PID=43193) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:41:16.791+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:41:16.792+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:41:16.792+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:41:25.018+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:41:25.014+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:41:25.021+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:41:25.036+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.246 seconds
[2023-09-04T01:41:55.166+0700] {processor.py:157} INFO - Started process (PID=43662) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:41:55.167+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:41:55.167+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:41:55.167+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:42:04.061+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:42:04.054+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:42:04.068+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:42:04.081+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.917 seconds
[2023-09-04T01:42:34.173+0700] {processor.py:157} INFO - Started process (PID=44118) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:42:34.174+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:42:34.175+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:42:34.175+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:42:43.259+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:42:43.255+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering or any similarly named keyspaces;
[2023-09-04T01:42:43.261+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:42:43.274+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 9.104 seconds
[2023-09-04T01:43:13.378+0700] {processor.py:157} INFO - Started process (PID=44531) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:43:13.379+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:43:13.380+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:43:13.379+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:43:22.299+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:43:22.292+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering.tracking or any similarly named keyspace and table pairs;
[2023-09-04T01:43:22.302+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:43:22.316+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.944 seconds
[2023-09-04T01:43:52.464+0700] {processor.py:157} INFO - Started process (PID=44956) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:43:52.464+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:43:52.465+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:43:52.465+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:44:01.353+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:44:01.348+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 141, in <module>
    cassandra_latest = retrieve_cassandra_latest_time()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 106, in retrieve_cassandra_latest_time
    df = spark.read.format("org.apache.spark.sql.cassandra").options(table="tracking", keyspace="Data_Engineering").load()
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 184, in load
    return self._df(self._jreader.load())
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Couldn't find Data_Engineering.tracking or any similarly named keyspace and table pairs;
[2023-09-04T01:44:01.356+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:44:01.372+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.909 seconds
[2023-09-04T01:44:31.465+0700] {processor.py:157} INFO - Started process (PID=45401) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:44:31.465+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:44:31.466+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:44:31.466+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:44:42.361+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:44:42.361+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T01:44:48.471+0700] {logging_mixin.py:151} INFO - ------------------Retrieve data from Cassandra------------------
[2023-09-04T01:44:48.521+0700] {logging_mixin.py:151} INFO - ------------------Processing data------------------
[2023-09-04T01:44:49.085+0700] {logging_mixin.py:151} INFO - ------------------Processing click data------------------
[2023-09-04T01:44:49.178+0700] {logging_mixin.py:151} INFO - ------------------Processing conversion data------------------
[2023-09-04T01:44:49.236+0700] {logging_mixin.py:151} INFO - ------------------Processing qualified data------------------
[2023-09-04T01:44:49.293+0700] {logging_mixin.py:151} INFO - ------------------Processing unqualified data------------------
[2023-09-04T01:44:49.331+0700] {logging_mixin.py:151} INFO - ------------------Processing cassandra data------------------
[2023-09-04T01:44:49.394+0700] {logging_mixin.py:151} INFO - ------------------Processing company data------------------
[2023-09-04T01:44:49.972+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:44:49.970+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 143, in <module>
    main(gen_latest)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 130, in main
    result = process_result(df)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 95, in process_result
    company_data = company_data_from_redshift()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 74, in company_data_from_redshift
    df = spark.read.csv("s3a://recruitment-project-tmph2003/company.csv", header=True)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o289.csv.
: org.apache.hadoop.security.AccessControlException: Permission denied: s3n://recruitment-project-tmph2003/company.csv
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:449)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:427)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at org.apache.hadoop.fs.s3native.$Proxy31.retrieveMetadata(Unknown Source)
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:476)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)
	at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.jets3t.service.impl.rest.HttpException
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestHead(RestStorageService.java:942)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2148)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectDetailsImpl(RestStorageService.java:2075)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:1093)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:548)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:174)
	... 27 more
[2023-09-04T01:44:49.972+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:44:49.984+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 18.523 seconds
[2023-09-04T01:45:20.108+0700] {processor.py:157} INFO - Started process (PID=46280) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:45:20.108+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:45:20.110+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:45:20.109+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:45:31.790+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:45:31.790+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T01:45:38.073+0700] {logging_mixin.py:151} INFO - ------------------Retrieve data from Cassandra------------------
[2023-09-04T01:45:38.131+0700] {logging_mixin.py:151} INFO - ------------------Processing data------------------
[2023-09-04T01:45:38.640+0700] {logging_mixin.py:151} INFO - ------------------Processing click data------------------
[2023-09-04T01:45:38.732+0700] {logging_mixin.py:151} INFO - ------------------Processing conversion data------------------
[2023-09-04T01:45:38.781+0700] {logging_mixin.py:151} INFO - ------------------Processing qualified data------------------
[2023-09-04T01:45:38.821+0700] {logging_mixin.py:151} INFO - ------------------Processing unqualified data------------------
[2023-09-04T01:45:38.862+0700] {logging_mixin.py:151} INFO - ------------------Processing cassandra data------------------
[2023-09-04T01:45:38.930+0700] {logging_mixin.py:151} INFO - ------------------Processing company data------------------
[2023-09-04T01:45:39.439+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:45:39.438+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 143, in <module>
    main(gen_latest)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 130, in main
    result = process_result(df)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 95, in process_result
    company_data = company_data_from_redshift()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 74, in company_data_from_redshift
    df = spark.read.csv("s3a://recruitment-project-tmph2003/company.csv", header=True)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o289.csv.
: org.apache.hadoop.security.AccessControlException: Permission denied: s3n://recruitment-project-tmph2003/company.csv
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:449)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:427)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at org.apache.hadoop.fs.s3native.$Proxy31.retrieveMetadata(Unknown Source)
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:476)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)
	at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.jets3t.service.impl.rest.HttpException
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestHead(RestStorageService.java:942)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2148)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectDetailsImpl(RestStorageService.java:2075)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:1093)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:548)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:174)
	... 27 more
[2023-09-04T01:45:39.440+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:45:39.452+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 19.351 seconds
[2023-09-04T01:46:09.615+0700] {processor.py:157} INFO - Started process (PID=47086) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:46:09.616+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:46:09.617+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:46:09.616+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:46:20.641+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:46:20.641+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T01:46:27.302+0700] {logging_mixin.py:151} INFO - ------------------Retrieve data from Cassandra------------------
[2023-09-04T01:46:27.351+0700] {logging_mixin.py:151} INFO - ------------------Processing data------------------
[2023-09-04T01:46:27.898+0700] {logging_mixin.py:151} INFO - ------------------Processing click data------------------
[2023-09-04T01:46:27.991+0700] {logging_mixin.py:151} INFO - ------------------Processing conversion data------------------
[2023-09-04T01:46:28.041+0700] {logging_mixin.py:151} INFO - ------------------Processing qualified data------------------
[2023-09-04T01:46:28.091+0700] {logging_mixin.py:151} INFO - ------------------Processing unqualified data------------------
[2023-09-04T01:46:28.133+0700] {logging_mixin.py:151} INFO - ------------------Processing cassandra data------------------
[2023-09-04T01:46:28.202+0700] {logging_mixin.py:151} INFO - ------------------Processing company data------------------
[2023-09-04T01:46:28.811+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:46:28.810+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 143, in <module>
    main(gen_latest)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 130, in main
    result = process_result(df)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 95, in process_result
    company_data = company_data_from_redshift()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 74, in company_data_from_redshift
    df = spark.read.csv("s3a://recruitment-project-tmph2003/company.csv", header=True)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o289.csv.
: org.apache.hadoop.security.AccessControlException: Permission denied: s3n://recruitment-project-tmph2003/company.csv
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:449)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:427)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at org.apache.hadoop.fs.s3native.$Proxy31.retrieveMetadata(Unknown Source)
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:476)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)
	at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.jets3t.service.impl.rest.HttpException
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestHead(RestStorageService.java:942)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2148)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectDetailsImpl(RestStorageService.java:2075)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:1093)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:548)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:174)
	... 27 more
[2023-09-04T01:46:28.812+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:46:28.826+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 19.214 seconds
[2023-09-04T01:46:58.928+0700] {processor.py:157} INFO - Started process (PID=47998) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:46:58.929+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:46:58.930+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:46:58.930+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:47:10.279+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:47:10.278+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T01:47:16.547+0700] {logging_mixin.py:151} INFO - ------------------Retrieve data from Cassandra------------------
[2023-09-04T01:47:16.598+0700] {logging_mixin.py:151} INFO - ------------------Processing data------------------
[2023-09-04T01:47:17.090+0700] {logging_mixin.py:151} INFO - ------------------Processing click data------------------
[2023-09-04T01:47:17.184+0700] {logging_mixin.py:151} INFO - ------------------Processing conversion data------------------
[2023-09-04T01:47:17.235+0700] {logging_mixin.py:151} INFO - ------------------Processing qualified data------------------
[2023-09-04T01:47:17.288+0700] {logging_mixin.py:151} INFO - ------------------Processing unqualified data------------------
[2023-09-04T01:47:17.332+0700] {logging_mixin.py:151} INFO - ------------------Processing cassandra data------------------
[2023-09-04T01:47:17.383+0700] {logging_mixin.py:151} INFO - ------------------Processing company data------------------
[2023-09-04T01:47:17.922+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:47:17.919+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 143, in <module>
    main(gen_latest)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 130, in main
    result = process_result(df)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 95, in process_result
    company_data = company_data_from_redshift()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 74, in company_data_from_redshift
    df = spark.read.csv("s3a://recruitment-project-tmph2003/company.csv", header=True)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o289.csv.
: org.apache.hadoop.security.AccessControlException: Permission denied: s3n://recruitment-project-tmph2003/company.csv
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:449)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:427)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at org.apache.hadoop.fs.s3native.$Proxy31.retrieveMetadata(Unknown Source)
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:476)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)
	at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.jets3t.service.impl.rest.HttpException
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestHead(RestStorageService.java:942)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2148)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectDetailsImpl(RestStorageService.java:2075)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:1093)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:548)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:174)
	... 27 more
[2023-09-04T01:47:17.923+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:47:17.934+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 19.009 seconds
[2023-09-04T01:47:48.048+0700] {processor.py:157} INFO - Started process (PID=48838) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:47:48.048+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:47:48.049+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:47:48.049+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:47:59.837+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:47:59.837+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T01:48:06.208+0700] {logging_mixin.py:151} INFO - ------------------Retrieve data from Cassandra------------------
[2023-09-04T01:48:06.267+0700] {logging_mixin.py:151} INFO - ------------------Processing data------------------
[2023-09-04T01:48:06.755+0700] {logging_mixin.py:151} INFO - ------------------Processing click data------------------
[2023-09-04T01:48:06.828+0700] {logging_mixin.py:151} INFO - ------------------Processing conversion data------------------
[2023-09-04T01:48:06.876+0700] {logging_mixin.py:151} INFO - ------------------Processing qualified data------------------
[2023-09-04T01:48:06.920+0700] {logging_mixin.py:151} INFO - ------------------Processing unqualified data------------------
[2023-09-04T01:48:06.968+0700] {logging_mixin.py:151} INFO - ------------------Processing cassandra data------------------
[2023-09-04T01:48:07.024+0700] {logging_mixin.py:151} INFO - ------------------Processing company data------------------
[2023-09-04T01:48:07.588+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:48:07.587+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from ETL_Cassandra_S3 import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 143, in <module>
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 130, in main
    result = process_result(df)
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 95, in process_result
    company_data = company_data_from_redshift()
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/ETL_Cassandra_S3.py", line 74, in company_data_from_redshift
    df = spark.read.csv("s3a://recruitment-project-tmph2003/company.csv", header=True)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o289.csv.
: org.apache.hadoop.security.AccessControlException: Permission denied: s3n://recruitment-project-tmph2003/company.csv
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:449)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.processException(Jets3tNativeFileSystemStore.java:427)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.handleException(Jets3tNativeFileSystemStore.java:411)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at org.apache.hadoop.fs.s3native.$Proxy31.retrieveMetadata(Unknown Source)
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:476)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:1439)
	at org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:47)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:723)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.jets3t.service.impl.rest.HttpException
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:519)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRequest(RestStorageService.java:281)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.performRestHead(RestStorageService.java:942)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectImpl(RestStorageService.java:2148)
	at org.jets3t.service.impl.rest.httpclient.RestStorageService.getObjectDetailsImpl(RestStorageService.java:2075)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:1093)
	at org.jets3t.service.StorageService.getObjectDetails(StorageService.java:548)
	at org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:174)
	... 27 more
[2023-09-04T01:48:07.589+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:48:07.600+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 19.554 seconds
[2023-09-04T01:48:37.764+0700] {processor.py:157} INFO - Started process (PID=49695) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:48:37.765+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:48:37.767+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:48:37.766+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:48:46.021+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:48:46.016+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
[2023-09-04T01:48:46.022+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:48:46.035+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.274 seconds
[2023-09-04T01:49:16.165+0700] {processor.py:157} INFO - Started process (PID=50101) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:49:16.165+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:49:16.166+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:49:16.166+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:49:23.972+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:49:23.969+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 1, in <module>
    import psycopg2
ModuleNotFoundError: No module named 'psycopg2'
[2023-09-04T01:49:23.972+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:49:23.986+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.823 seconds
[2023-09-04T01:49:54.161+0700] {processor.py:157} INFO - Started process (PID=50581) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:49:54.162+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:49:54.163+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:49:54.163+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:50:01.612+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:50:01.610+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 16, in <module>
    with open('create_redshift_schema.sql', 'r') as sql_file:
FileNotFoundError: [Errno 2] No such file or directory: 'create_redshift_schema.sql'
[2023-09-04T01:50:01.612+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:50:01.624+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.468 seconds
[2023-09-04T01:50:31.732+0700] {processor.py:157} INFO - Started process (PID=50950) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:50:31.732+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:50:31.733+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:50:31.733+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:50:39.148+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:50:39.147+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 16, in <module>
    with open('create_redshift_schema.sql', 'r') as sql_file:
FileNotFoundError: [Errno 2] No such file or directory: 'create_redshift_schema.sql'
[2023-09-04T01:50:39.148+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:50:39.161+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.431 seconds
[2023-09-04T01:51:09.351+0700] {processor.py:157} INFO - Started process (PID=51273) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:09.352+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:51:09.353+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:51:09.353+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:16.611+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:51:16.609+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 16, in <module>
    with open('./create_redshift_schema.sql', 'r') as sql_file:
FileNotFoundError: [Errno 2] No such file or directory: './create_redshift_schema.sql'
[2023-09-04T01:51:16.611+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:16.622+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.276 seconds
[2023-09-04T01:51:46.729+0700] {processor.py:157} INFO - Started process (PID=51750) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:46.730+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:51:46.731+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:51:46.731+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:53.740+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:51:53.737+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 16
    sql_command = "CREATE TABLE IF NOT EXISTS result (
                  ^
SyntaxError: unterminated string literal (detected at line 16)
[2023-09-04T01:51:53.741+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:51:53.756+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.031 seconds
[2023-09-04T01:52:23.937+0700] {processor.py:157} INFO - Started process (PID=52076) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:52:23.938+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:52:23.939+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:52:23.939+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:52:31.334+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:52:31.332+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 16
    sql_command = "CREATE TABLE IF NOT EXISTS result (
                  ^
SyntaxError: unterminated string literal (detected at line 16)
[2023-09-04T01:52:31.335+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:52:31.349+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.416 seconds
[2023-09-04T01:53:01.530+0700] {processor.py:157} INFO - Started process (PID=52410) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:53:01.531+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:53:01.531+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:53:01.531+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:55:19.950+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:55:19.944+0700] {timeout.py:68} ERROR - Process timed out, PID: 52410
[2023-09-04T01:55:19.952+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:55:19.950+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 33, in <module>
    """
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 52410
[2023-09-04T01:55:19.953+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:55:19.973+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 138.444 seconds
[2023-09-04T01:55:50.142+0700] {processor.py:157} INFO - Started process (PID=52867) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:55:50.142+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:55:50.143+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:55:50.142+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:58:07.878+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:58:07.875+0700] {timeout.py:68} ERROR - Process timed out, PID: 52867
[2023-09-04T01:58:07.879+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:58:07.878+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 36, in <module>
    conn = psycopg2.connect(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 52867
[2023-09-04T01:58:07.879+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:58:07.892+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 137.752 seconds
[2023-09-04T01:58:38.058+0700] {processor.py:157} INFO - Started process (PID=53357) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T01:58:38.059+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T01:58:38.059+0700] {logging_mixin.py:151} INFO - [2023-09-04T01:58:38.059+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:01:01.957+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:01:01.956+0700] {timeout.py:68} ERROR - Process timed out, PID: 53357
[2023-09-04T02:01:01.959+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:01:01.958+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 36, in <module>
    conn = psycopg2.connect(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 53357
[2023-09-04T02:01:01.959+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:01:01.975+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 143.920 seconds
[2023-09-04T02:01:32.098+0700] {processor.py:157} INFO - Started process (PID=53921) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:01:32.099+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:01:32.100+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:01:32.100+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:03:49.896+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:03:49.892+0700] {timeout.py:68} ERROR - Process timed out, PID: 53921
[2023-09-04T02:03:49.899+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:03:49.897+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 36, in <module>
    conn = psycopg2.connect(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 53921
[2023-09-04T02:03:49.899+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:03:49.918+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 137.824 seconds
[2023-09-04T02:04:20.027+0700] {processor.py:157} INFO - Started process (PID=54345) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:04:20.027+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:04:20.029+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:04:20.028+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:06:37.831+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:06:37.828+0700] {timeout.py:68} ERROR - Process timed out, PID: 54345
[2023-09-04T02:06:37.834+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:06:37.832+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 36, in <module>
    host=redshift_host,
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import create_redshift
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 54345
[2023-09-04T02:06:37.835+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:06:37.851+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 137.829 seconds
[2023-09-04T02:07:07.930+0700] {processor.py:157} INFO - Started process (PID=54707) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:07:07.931+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:07:07.931+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:07:07.931+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:09:25.767+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:09:25.764+0700] {timeout.py:68} ERROR - Process timed out, PID: 54707
[2023-09-04T02:09:25.769+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:09:25.767+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 35, in <module>
    conn = psycopg2.connect(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import fake_data
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 54707
[2023-09-04T02:09:25.769+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:09:25.789+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 137.861 seconds
[2023-09-04T02:09:26.946+0700] {processor.py:157} INFO - Started process (PID=55444) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:09:26.946+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:09:26.946+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:09:26.946+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:09:34.899+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:09:34.891+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 9, in <module>
    'retry_delay' : timedelta(minutes = 2)
NameError: name 'timedelta' is not defined
[2023-09-04T02:09:34.906+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:09:34.919+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.975 seconds
[2023-09-04T02:10:05.204+0700] {processor.py:157} INFO - Started process (PID=55835) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:05.205+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:10:05.206+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:05.206+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:13.130+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:13.122+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 9, in <module>
    'retry_delay' : timedelta(minutes = 2)
NameError: name 'timedelta' is not defined
[2023-09-04T02:10:13.136+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:13.150+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.950 seconds
[2023-09-04T02:10:37.491+0700] {processor.py:157} INFO - Started process (PID=56198) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:37.491+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:10:37.493+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:37.492+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:45.988+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:45.988+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:10:46.133+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:46.132+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import fake_data
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:10:46.133+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:46.142+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.656 seconds
[2023-09-04T02:10:57.328+0700] {processor.py:157} INFO - Started process (PID=56521) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:10:57.329+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:10:57.331+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:10:57.330+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:05.390+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:05.390+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:11:05.509+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:05.509+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    import fake_data
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:11:05.509+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:05.520+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.195 seconds
[2023-09-04T02:11:13.695+0700] {processor.py:157} INFO - Started process (PID=56859) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:13.696+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:11:13.697+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:13.696+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:21.717+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:21.716+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 8, 29),
TypeError: 'module' object is not callable
[2023-09-04T02:11:21.718+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:21.731+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.039 seconds
[2023-09-04T02:11:48.038+0700] {processor.py:157} INFO - Started process (PID=57253) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:48.038+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:11:48.040+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:48.039+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:55.791+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:11:55.790+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:11:55.792+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:11:55.804+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.771 seconds
[2023-09-04T02:12:02.961+0700] {processor.py:157} INFO - Started process (PID=57572) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:02.962+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:12:02.962+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:12:02.962+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:10.205+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:12:10.203+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:12:10.205+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:10.221+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.263 seconds
[2023-09-04T02:12:19.454+0700] {processor.py:157} INFO - Started process (PID=57892) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:19.454+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:12:19.455+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:12:19.455+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:26.874+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:12:26.872+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:12:26.874+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:26.887+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.435 seconds
[2023-09-04T02:12:57.064+0700] {processor.py:157} INFO - Started process (PID=58250) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:12:57.065+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:12:57.066+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:12:57.065+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:04.302+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:04.300+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:13:04.302+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:04.315+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.255 seconds
[2023-09-04T02:13:34.451+0700] {processor.py:157} INFO - Started process (PID=58584) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:34.452+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:13:34.452+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:34.452+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:42.002+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:42.000+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:13:42.002+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:42.018+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.568 seconds
[2023-09-04T02:13:43.131+0700] {processor.py:157} INFO - Started process (PID=58902) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:43.131+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:13:43.132+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:43.132+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:50.698+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:50.696+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 14, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:13:50.699+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:50.739+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.612 seconds
[2023-09-04T02:13:59.188+0700] {processor.py:157} INFO - Started process (PID=59214) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:13:59.189+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:13:59.189+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:13:59.189+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:07.205+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:14:07.203+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 14, in <module>
    schedule_interval = '@daily'
TypeError: 'module' object is not callable
[2023-09-04T02:14:07.205+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:07.218+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.032 seconds
[2023-09-04T02:14:37.453+0700] {processor.py:157} INFO - Started process (PID=59598) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:37.454+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:14:37.456+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:14:37.455+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:44.807+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:14:44.805+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:14:44.807+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:44.821+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.372 seconds
[2023-09-04T02:14:54.023+0700] {processor.py:157} INFO - Started process (PID=59918) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:14:54.024+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:14:54.025+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:14:54.024+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:01.936+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:15:01.934+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:15:01.936+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:01.949+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.930 seconds
[2023-09-04T02:15:09.167+0700] {processor.py:157} INFO - Started process (PID=60239) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:09.167+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:15:09.168+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:15:09.168+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:16.975+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:15:16.973+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 4),
TypeError: 'module' object is not callable
[2023-09-04T02:15:16.975+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:16.988+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.823 seconds
[2023-09-04T02:15:47.210+0700] {processor.py:157} INFO - Started process (PID=60598) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:47.211+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:15:47.212+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:15:47.211+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:55.073+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:15:55.071+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date = datetime(2023, 9, 4),
TypeError: 'module' object is not callable
[2023-09-04T02:15:55.073+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:15:55.086+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.877 seconds
[2023-09-04T02:16:01.213+0700] {processor.py:157} INFO - Started process (PID=60907) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:01.214+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:16:01.214+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:01.214+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:08.951+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:08.949+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 13, in <module>
    start_date=datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:16:08.951+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:08.964+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.753 seconds
[2023-09-04T02:16:17.176+0700] {processor.py:157} INFO - Started process (PID=61223) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:17.176+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:16:17.177+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:17.177+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:25.189+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:25.187+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 12, in <module>
    start_date=datetime(2023, 9, 3),
TypeError: 'module' object is not callable
[2023-09-04T02:16:25.189+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:25.210+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.036 seconds
[2023-09-04T02:16:39.500+0700] {processor.py:157} INFO - Started process (PID=61551) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:39.500+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:16:39.501+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:39.500+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:46.671+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:16:46.899+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.899+0700] {manager.py:501} INFO - Created Permission View: can delete on DAG:ETL_cassandra_s3_dag
[2023-09-04T02:16:46.908+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.908+0700] {manager.py:501} INFO - Created Permission View: can read on DAG:ETL_cassandra_s3_dag
[2023-09-04T02:16:46.915+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.915+0700] {manager.py:501} INFO - Created Permission View: can edit on DAG:ETL_cassandra_s3_dag
[2023-09-04T02:16:46.921+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.921+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:16:46.925+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.925+0700] {dag.py:2929} INFO - Creating ORM DAG for ETL_cassandra_s3_dag
[2023-09-04T02:16:46.931+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:16:46.931+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:16:46.948+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.450 seconds
[2023-09-04T02:17:09.199+0700] {processor.py:157} INFO - Started process (PID=61877) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:09.200+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:17:09.200+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:09.200+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:16.584+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:16.590+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:16.589+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:17:16.614+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:16.614+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:17:16.637+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.442 seconds
[2023-09-04T02:17:46.985+0700] {processor.py:157} INFO - Started process (PID=62193) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:46.986+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:17:46.987+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:46.987+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:54.858+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:55.014+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:55.014+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:17:55.025+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:55.025+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:17:55.039+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.058 seconds
[2023-09-04T02:17:56.157+0700] {processor.py:157} INFO - Started process (PID=62506) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:17:56.158+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:17:56.159+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:17:56.158+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:03.314+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:03.508+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:03.508+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:18:03.519+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:03.519+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:18:03.533+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.380 seconds
[2023-09-04T02:18:23.736+0700] {processor.py:157} INFO - Started process (PID=62845) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:23.737+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:18:23.739+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:23.738+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:30.868+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:30.865+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 26, in <module>
    Load = PythonOperator(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to PythonOperator (task_id: Load_data_to_s3). Invalid arguments were:
**kwargs: {'task_name': 'Load_data_to_s3'}
[2023-09-04T02:18:30.869+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:30.881+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.148 seconds
[2023-09-04T02:18:52.111+0700] {processor.py:157} INFO - Started process (PID=63163) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:52.112+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:18:52.113+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:52.113+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:59.807+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:18:59.806+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 15, in <module>
    Extract = PythonOperator(
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/operators/python.py", line 177, in __init__
    super().__init__(**kwargs)
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: BaseOperator.__init__() missing 1 required positional argument: 'task_id'
[2023-09-04T02:18:59.808+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:18:59.820+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.713 seconds
[2023-09-04T02:19:27.096+0700] {processor.py:157} INFO - Started process (PID=63482) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:27.097+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:19:27.098+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:27.097+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:34.444+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:34.589+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:34.589+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:19:34.603+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:34.602+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:19:34.620+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.525 seconds
[2023-09-04T02:19:40.807+0700] {processor.py:157} INFO - Started process (PID=63779) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:40.807+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:19:40.808+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:40.807+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:48.772+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:19:48.934+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:48.934+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:19:48.945+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:19:48.945+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:19:48.960+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.155 seconds
[2023-09-04T02:20:19.156+0700] {processor.py:157} INFO - Started process (PID=64115) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:20:19.157+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:20:19.158+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:20:19.157+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:20:26.746+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:20:26.890+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:20:26.890+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:20:26.901+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:20:26.901+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:20:26.915+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.762 seconds
[2023-09-04T02:20:57.066+0700] {processor.py:157} INFO - Started process (PID=64461) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:20:57.067+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:20:57.068+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:20:57.068+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:21:04.802+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:21:04.959+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:21:04.959+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:21:04.971+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:21:04.971+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:21:04.987+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.923 seconds
[2023-09-04T02:21:06.136+0700] {processor.py:157} INFO - Started process (PID=64773) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:21:06.136+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:21:06.137+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:21:06.137+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:23:25.447+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:23:25.444+0700] {timeout.py:68} ERROR - Process timed out, PID: 64773
[2023-09-04T02:23:25.450+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:23:25.448+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/create_redshift.py", line 35, in <module>
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection timed out
	Is the server running on host "redshift-cluster-1.cvzjnn720rwg.ap-southeast-1.redshift.amazonaws.com" (172.31.35.174) and accepting
	TCP/IP connections on port 5439?


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 4, in <module>
    from create_redshift import *
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 64773
[2023-09-04T02:23:25.451+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:23:25.471+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 139.337 seconds
[2023-09-04T02:23:28.624+0700] {processor.py:157} INFO - Started process (PID=65194) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:23:28.625+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:23:28.626+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:23:28.625+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:23:37.056+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:23:37.110+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:23:37.110+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:23:37.121+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:23:37.121+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:23:37.139+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.521 seconds
[2023-09-04T02:24:07.375+0700] {processor.py:157} INFO - Started process (PID=65584) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:07.376+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:24:07.377+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:07.376+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:14.885+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:14.896+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:14.895+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:24:14.906+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:14.906+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:24:14.919+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.550 seconds
[2023-09-04T02:24:28.088+0700] {processor.py:157} INFO - Started process (PID=65908) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:28.088+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:24:28.089+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:28.089+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:35.787+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:35.798+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:35.798+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:24:35.808+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:35.808+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:24:35.822+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.736 seconds
[2023-09-04T02:24:44.066+0700] {processor.py:157} INFO - Started process (PID=66278) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:44.067+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:24:44.067+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:44.067+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:52.368+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:24:52.379+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:52.379+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:24:52.389+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:24:52.389+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:24:52.403+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.338 seconds
[2023-09-04T02:25:15.726+0700] {processor.py:157} INFO - Started process (PID=66608) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:25:15.726+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:25:15.727+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:25:15.727+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:25:23.297+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:25:23.355+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:25:23.354+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:25:23.365+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:25:23.365+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:25:23.379+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.656 seconds
[2023-09-04T02:25:53.510+0700] {processor.py:157} INFO - Started process (PID=66992) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:25:53.511+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:25:53.511+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:25:53.511+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:26:01.417+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:26:01.428+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:26:01.428+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:26:01.439+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:26:01.439+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:26:01.452+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.943 seconds
[2023-09-04T02:26:27.770+0700] {processor.py:157} INFO - Started process (PID=67361) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:26:27.771+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:26:27.772+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:26:27.771+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:26:36.099+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:26:36.099+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:26:36.214+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:26:36.213+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 16, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:26:36.214+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:26:36.226+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.458 seconds
[2023-09-04T02:27:06.375+0700] {processor.py:157} INFO - Started process (PID=67696) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:06.376+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:27:06.377+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:06.377+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:14.934+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:14.934+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:27:15.033+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:15.032+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 16, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:27:15.033+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:15.043+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.672 seconds
[2023-09-04T02:27:45.172+0700] {processor.py:157} INFO - Started process (PID=68039) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:45.173+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:27:45.174+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:45.173+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:53.956+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:53.955+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:27:54.060+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:54.060+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 16, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:27:54.061+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:54.070+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.903 seconds
[2023-09-04T02:27:55.137+0700] {processor.py:157} INFO - Started process (PID=68368) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:27:55.138+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:27:55.138+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:27:55.138+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:03.467+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:03.467+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:28:03.571+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:03.570+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 16, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:28:03.571+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:03.582+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.446 seconds
[2023-09-04T02:28:33.919+0700] {processor.py:157} INFO - Started process (PID=68730) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:33.920+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:28:33.920+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:33.920+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:41.937+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:41.937+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:28:42.038+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:42.038+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 16, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:28:42.039+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:42.048+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.130 seconds
[2023-09-04T02:28:59.349+0700] {processor.py:157} INFO - Started process (PID=69067) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:28:59.349+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:28:59.350+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:28:59.349+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:29:07.772+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:29:07.772+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:29:07.881+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:29:07.880+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:29:07.881+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:29:07.894+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.547 seconds
[2023-09-04T02:29:38.066+0700] {processor.py:157} INFO - Started process (PID=69412) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:29:38.066+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:29:38.067+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:29:38.067+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:29:46.221+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:29:46.221+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:29:46.323+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:29:46.323+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:29:46.324+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:29:46.333+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.272 seconds
[2023-09-04T02:30:16.470+0700] {processor.py:157} INFO - Started process (PID=69768) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:16.470+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:30:16.470+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:16.470+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:24.661+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:24.661+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:30:24.775+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:24.775+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:30:24.776+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:24.785+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.317 seconds
[2023-09-04T02:30:37.989+0700] {processor.py:157} INFO - Started process (PID=70096) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:37.990+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:30:37.991+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:37.991+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:45.679+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:45.679+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:30:45.780+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:45.780+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:30:45.781+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:45.790+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.805 seconds
[2023-09-04T02:30:54.954+0700] {processor.py:157} INFO - Started process (PID=70424) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:30:54.955+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:30:54.956+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:30:54.955+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:31:03.188+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:31:03.188+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:31:03.301+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:31:03.301+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:31:03.302+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:31:03.312+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.359 seconds
[2023-09-04T02:31:33.441+0700] {processor.py:157} INFO - Started process (PID=70851) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:31:33.442+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:31:33.442+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:31:33.442+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:31:41.010+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:31:41.010+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:31:41.119+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:31:41.118+0700] {dagbag.py:347} ERROR - Failed to import: /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
Traceback (most recent call last):
  File "/home/tmph2003/anaconda3/lib/python3.10/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py", line 5, in <module>
    from fake_data import *
  File "/home/tmph2003/Phuong_Data/Project1/airflow/dags/fake_data.py", line 19, in <module>
    import mysql.connector
ModuleNotFoundError: No module named 'mysql'
[2023-09-04T02:31:41.119+0700] {processor.py:841} WARNING - No viable dags retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:31:41.132+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 7.692 seconds
[2023-09-04T02:32:11.241+0700] {processor.py:157} INFO - Started process (PID=71191) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:11.242+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:32:11.243+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:11.243+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:19.420+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.420+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:32:19.532+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.532+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:32:19.534+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.534+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:32:19.543+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.543+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:32:19.569+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:19.687+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.687+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:32:19.695+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:19.695+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:32:19.714+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.477 seconds
[2023-09-04T02:32:49.833+0700] {processor.py:157} INFO - Started process (PID=71514) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:49.834+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:32:49.835+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:49.835+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:57.701+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.701+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:32:57.813+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.813+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:32:57.814+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.814+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:32:57.820+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.820+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:32:57.843+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:32:57.964+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.963+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:32:57.972+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:32:57.972+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:32:57.986+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.156 seconds
[2023-09-04T02:33:28.127+0700] {processor.py:157} INFO - Started process (PID=71851) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:33:28.128+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:33:28.129+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:28.128+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:33:36.176+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.176+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:33:36.284+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.284+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:33:36.285+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.285+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:33:36.291+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.291+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:33:36.312+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:33:36.434+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.434+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:33:36.443+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:36.443+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:33:36.458+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.336 seconds
[2023-09-04T02:33:57.777+0700] {processor.py:157} INFO - Started process (PID=72199) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:33:57.777+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:33:57.778+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:33:57.778+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:34:06.174+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.174+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:34:06.285+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.285+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:34:06.286+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.286+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:34:06.292+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.292+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:34:06.313+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:34:06.317+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.316+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:34:06.329+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:06.329+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:34:06.343+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.569 seconds
[2023-09-04T02:34:36.665+0700] {processor.py:157} INFO - Started process (PID=72712) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:34:36.665+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:34:36.666+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:36.666+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:34:45.279+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.279+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:34:45.400+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.399+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:34:45.401+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.401+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:34:45.406+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.406+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:34:45.426+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:34:45.478+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.478+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:34:45.559+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:34:45.559+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:34:45.573+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.910 seconds
[2023-09-04T02:35:15.676+0700] {processor.py:157} INFO - Started process (PID=73296) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:35:15.677+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:35:15.678+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:15.678+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:35:23.915+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:23.915+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:35:24.025+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:24.025+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:35:24.026+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:24.026+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:35:24.032+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:24.032+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:35:24.051+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:35:24.059+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:24.059+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:35:24.069+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:24.069+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:35:24.082+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.408 seconds
[2023-09-04T02:35:54.168+0700] {processor.py:157} INFO - Started process (PID=73867) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:35:54.168+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:35:54.169+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:35:54.169+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:36:02.118+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.118+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:36:02.236+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.236+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:36:02.238+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.237+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:36:02.243+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.243+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:36:02.267+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:36:02.394+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.393+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:36:02.403+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:02.402+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:36:02.417+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.251 seconds
[2023-09-04T02:36:32.561+0700] {processor.py:157} INFO - Started process (PID=74261) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:36:32.562+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:36:32.562+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:32.562+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:36:40.728+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:40.728+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:36:40.840+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:40.839+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:36:40.842+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:40.842+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:36:40.848+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:40.848+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:36:40.874+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:36:41.014+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:41.014+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:36:41.023+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:36:41.023+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:36:41.036+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.476 seconds
[2023-09-04T02:37:11.168+0700] {processor.py:157} INFO - Started process (PID=75603) to work on /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:37:11.170+0700] {processor.py:829} INFO - Processing file /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py for tasks to queue
[2023-09-04T02:37:11.171+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:11.170+0700] {dagbag.py:539} INFO - Filling up the DagBag from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:37:18.911+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:18.911+0700] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-09-04T02:37:19.017+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:19.017+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:37:19.018+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:19.018+0700] {fake_data.py:33} WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-09-04T02:37:19.023+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:19.023+0700] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-09-04T02:37:19.047+0700] {processor.py:839} INFO - DAG(s) dict_keys(['ETL_cassandra_s3_dag']) retrieved from /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py
[2023-09-04T02:37:19.165+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:19.164+0700] {dag.py:2907} INFO - Sync 1 DAGs
[2023-09-04T02:37:19.172+0700] {logging_mixin.py:151} INFO - [2023-09-04T02:37:19.172+0700] {dag.py:3677} INFO - Setting next_dagrun for ETL_cassandra_s3_dag to 2023-09-03T00:00:00+00:00, run_after=2023-09-04T00:00:00+00:00
[2023-09-04T02:37:19.185+0700] {processor.py:179} INFO - Processing /home/tmph2003/Phuong_Data/Project1/airflow/dags/dags_setup.py took 8.018 seconds
